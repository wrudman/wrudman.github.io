<html>
<head>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta charset="UTF-8">
    <title></title>
    <link rel="stylesheet" href="{{ '/assets/css/main.css' | relative_url }}">
    <link rel="stylesheet" href="{{ '/assets/css/garden.css' | relative_url }}"> 
    <style id="flower_css"></style>
</head>
<body>
    <!-- Research Garden -->
    <svg id="flower_template" xmlns="http://www.w3.org/2000/svg" viewBox="-10 -10 20 20">
        <ellipse rx="10" ry="20" transform="rotate(0)" fill="[[COLOR]]" class="petal [[FLOWER_CLASS]]"/>
        <ellipse rx="10" ry="20" transform="rotate(45)" fill="[[COLOR]]" class="petal [[FLOWER_CLASS]]"/>
        <ellipse rx="10" ry="20" transform="rotate(90)" fill="[[COLOR]]" class="petal [[FLOWER_CLASS]]"/>
        <ellipse rx="10" ry="20" transform="rotate(135)" fill="[[COLOR]]" class="petal [[FLOWER_CLASS]]"/>
        <ellipse rx="10" ry="20" transform="rotate(180)" fill="[[COLOR]]" class="petal [[FLOWER_CLASS]]"/>
        <ellipse rx="10" ry="20" transform="rotate(225)" fill="[[COLOR]]" class="petal [[FLOWER_CLASS]]"/>
        <ellipse rx="10" ry="20" transform="rotate(270)" fill="[[COLOR]]" class="petal [[FLOWER_CLASS]]"/>
        <ellipse rx="10" ry="20" transform="rotate(315)" fill="[[COLOR]]" class="petal [[FLOWER_CLASS]]"/>
        <circle r="6" fill="white"/>
    </svg>
    <div id="garden_title">William's Research Garden</div>
    <div id="garden_container">
        <svg id="garden" preserveAspectRatio="xMinYMin meet"></svg>
     </div>
     <div id="coauthor_hall_of_fame">
        <div id="coauthor_title">Recurrent Coauthors ("Hall of Friends")</div>
        <div id="coauthor_list"></div>
    </div>
    <div id="paper_modal">
        <!-- a close icon at the top right -->
        <div id="paper_modal_close" onclick="$('#paper_modal').fadeOut(200);">X</div>
        <div id="paper_modal_title"></div>
        <div id="paper_modal_venue"></div>
        <div id="paper_modal_content"></div>
        <div id="paper_modal_links"></div>
    </div>

    <script src="https://code.jquery.com/jquery-3.6.0.min.js"></script>

    <script src="assets/js/garden.js?v=2"></script>
    <script>
        var papers = [
        {"id": "isoscore", "title": "IsoScore", "venue": "ACL2022", "url": "https://arxiv.org/pdf/2108.07344", "root_node": 1, "root_name": "Representational Geometry\n2021-Present", "root_color": "#FA9189", "coauthors": ["Nate Gillman, Taylor Rayne, Carsten Eickhoff"], "full_title": "IsoScore: Measuring the Uniformity of Embedding Space Utilization", "summary": "My first conference paper! We develop IsoScore, the first metric capable of accurately measure isotropy, i.e., the uniformity of variance in embedding space. We show that existing methods for measuing isotorpy as fundamentally flawed and only IsoScore reliably measures isotropy."},     
        {"id": "outlier_dims", "title": "Outlier Dims", "venue": "EMNLP 2023", "url": "https://arxiv.org/pdf/2310.17715", "parent": "isoscore", "coauthors": ["Catherine Chen", "Carsten Eickhoff"], "full_title": "Outlier Dimensions Encode Task-Specific Knowledge", "summary": "Representations from large language models (LLMs) are known to be dominated by a small subset of dimensions with exceedingly high variance. Previous works have argued that although ablating these outlier dimensions in LLM representations hurts downstream performance, outlier dimensions are detrimental to the representational quality of embeddings. In this study, we investigate how fine-tuning impacts outlier dimensions and show that 1) outlier dimensions that occur in pre-training persist in fine-tuned models and 2) a single outlier dimension can complete downstream tasks with a minimal error rate. Our results suggest that outlier dimensions can encode crucial task-specific knowledge and that the value of a representation in a single outlier dimension drives downstream model decisions."},
          {"id": "garden_path", "title": "Garden Paths", "venue": "BlackboxNLP 2022", "url": "https://arxiv.org/abs/2205.12302", "parent": "outlier_dims", "coauthors": ["William Jurayj", "Carsten Eickhoff"], "full_title": "Garden-Path Traversal in GPT-2", "summary": "We present a collection of methods to analyze the hidden states of GPT-2 and use the model's navigation of garden path sentences as a case study. To enable this, we compile the largest currently available dataset of garden path sentences. We show that Manhattan distances and cosine similarities provide more reliable insights compared to established surprisal methods that analyze next-token probabilities computed by a language modeling head. Using these methods, we find that negating tokens have minimal impacts on the model's representations for unambiguous forms of sentences with ambiguity solely over what the object of a verb is, but have a more substantial impact of representations for unambiguous sentences whose ambiguity would stem from the voice of a verb. "},
        {"id": "istar", "title": "I-STAR", "venue": "ICLR 2024", "url": "https://arxiv.org/abs/2305.19358", "parent": "outlier_dims", "coauthors": ["Carsten Eickhoff"], "full_title": "Stable Anisotropic Regularization", "summary": " Several studies in Natural Language Processing (NLP) have sought to mitigate the impact of such outlier dimensions and force LLMs to be isotropic (i.e., have uniform variance across all dimensions in embedding space). Isotropy is thought to be a desirable property for LLMs that improves model performance and more closely aligns textual representations with human intuition. However, many of the claims regarding isotropy in NLP have been based on the average cosine similarity of embeddings, which has recently been shown to be a flawed measure of isotropy. In this paper, we propose I-STAR: IsoScore*-based STable Anisotropic Regularization, a novel regularization method that can be used to increase or decrease levels of isotropy in embedding space during training. I-STAR uses IsoScore*, the first accurate measure of isotropy that is both differentiable and stable on mini-batch computations. In contrast to several previous works, we find that decreasing isotropy in contextualized embeddings improves performance on the majority of tasks and models considered in this paper."},
        {"id": "trim", "title": "TRIM", "venue": "Submitted to EACL 2025", "url": "https://arxiv.org/pdf/2505.16743", "parent": "istar", "coauthors": ["Florentin Beck", "Carsten Eickhoff"], "full_title": "TRIM: Achieving Extreme Sparsity with Targeted Row-wise Iterative Metric-driven Pruning", "summary": "This work introduces TRIM (Targeted Row-wise Iterative Metric-driven pruning), a novel approach that applies varying sparsity ratios to individual output dimensions (rows) within each layer. TRIM employs an iterative adjustment process guided by quality metrics to optimize dimension-wise sparsity allocation, focusing on reducing variance in quality retention across outputs to preserve critical information. TRIM can be seamlessly integrated with existing layer-wise pruning strategies. Our evaluations on perplexity and zero-shot tasks across diverse LLM families (Qwen2.5, LLaMA-2, and OPT) and sparsity levels demonstrate that TRIM achieves new state-of-the-art results and enhances stability. For instance, at 80% sparsity, TRIM reduces perplexity by 48% for Qwen2.5-14B and over 90% for OPT-13B compared to baseline methods. We conclude that fine-grained, dimension-wise sparsity adaptation is crucial for pushing the limits of extreme LLM compression.", "children": []}, 
        {"id": "notice", "title": "NOTICE", "venue": "NAACL 2025", "url": "https://arxiv.org/pdf/2406.16320", "root_node": 1, "root_name": "Multimodal Mech Interp\n2024-Present", "root_color": "#FFE699", "coauthors": ["Michal Golovanevsky", "Vedant Palit", "Ritambhara Singh", "Carsten Eickhoff"], "full_title": "What Do VLMs NOTICE? A Mechanistic Interpretability Pipeline for Gaussian-Noise-free Text-Image Corruption and Evaluation", "summary": " We introduce NOTICE, the first Noise-free Text-Image Corruption and Evaluation pipeline for mechanistic interpretability in VLMs. NOTICE incorporates a Semantic Minimal Pairs (SMP) framework for image corruption and Symmetric Token Replacement (STR) for text. This approach enables semantically meaningful causal mediation analysis for both modalities, providing a robust method for analyzing multimodal integration within models like BLIP. Our experiments on the SVO-Probes, MIT-States, and Facial Expression Recognition datasets reveal crucial insights into VLM decision-making, identifying the significant role of middle-layer cross-attention heads. Further, we uncover a set of ``universal cross-attention heads'' that consistently contribute across tasks and modalities, each performing distinct functions such as implicit image segmentation, object inhibition, and outlier inhibition. This work paves the way for more transparent and interpretable multimodal systems."},
        {"id": "pvp", "title": "Visual CounterFact", "venue": "EMNLP 2025", "url": "https://arxiv.org/abs/2505.17127", "parent": "notice", "coauthors": ["Michal Golovanevsky", "Vedant Palit", "Michael Lepori", "Amir Bar", "Ritambhara Singh", "Carsten Eickhoff"], "full_title": "Pixels Versus Priors: Controlling Knowledge Priors in Vision-Language Models through Visual Counterfacts", "summary": " We introduce Visual CounterFact, a new dataset of visually-realistic counterfactuals that put world knowledge priors (e.g, red strawberry) into direct conflict with visual input (e.g, blue strawberry). Using Visual CounterFact, we show that model predictions initially reflect memorized priors, but shift toward visual evidence in mid-to-late layers. This dynamic reveals a competition between the two modalities, with visual input ultimately overriding priors during evaluation. To control this behavior, we propose Pixels Versus Priors (PvP) steering vectors, a mechanism for controlling model outputs toward either world knowledge or visual input through activation-level interventions. On average, PvP successfully shifts 99.3% of color and 80.8% of size predictions from priors to counterfactuals. Together, these findings offer new tools for interpreting and controlling factual behavior in multimodal models."},
        {"id": "shape_blind", "title": "Forgotten Polygons", "venue": "ACL 2025", "url": "https://arxiv.org/abs/2502.15969", "parent": "notice", "coauthors": ["Michal Golovanevsky", "Vedant Palit", "Yann Lecun", "Amir Bar", "Ritambhara Singh", "Carsten Eickhoff"], "full_title": "Forgotten Polygons: Multimodal Large Language Models are Shape-Blind", "summary": " Our findings reveal fundamental shortcomings in shape recognition, with top models achieving under 50% accuracy in identifying regular polygons. We analyze these failures through the lens of dual-process theory and show that MLLMs rely on System 1 (intuitive, memorized associations) rather than System 2 (deliberate reasoning). Consequently, MLLMs fail to count the sides of both familiar and novel shapes, suggesting they have neither learned the concept of sides nor effectively process visual inputs. Finally, we propose Visually Cued Chain-of-Thought (VC-CoT) prompting, which enhances multi-step mathematical reasoning by explicitly referencing visual annotations in diagrams, boosting GPT-4o's accuracy on an irregular polygon side-counting task from 7% to 93%. Our findings suggest that System 2 reasoning in MLLMs remains an open problem, and visually-guided prompting is essential for successfully engaging visual reasoning."},
        {"id": "app", "title": "APP", "venue": "Submitted to EACL 2025", "url": "https://arxiv.org/pdf/2511.05442", "parent": "pvp", "coauthors": ["Frauke Andersen", "Ruochen Zhang", "Carsten Eickhoff"], "full_title": "APP: Accelerated Path Patching with Task-Specific Pruning", "summary": "Circuit discovery is a key step in many mechanistic interpretability pipelines. Current methods, such as Path Patching, are computationally expensive and have limited in-depth circuit analysis for smaller models. In this study, we propose Accelerated Path Patching (APP), a hybrid approach leveraging our novel contrastive attention head pruning method to drastically reduce the search space of circuit discovery methods. Our Contrastive-FLAP pruning algorithm uses techniques from causal mediation analysis to assign higher pruning scores to task-specific attention heads, leading to higher performing sparse models compared to traditional pruning techniques. Although Contrastive-FLAP is successful at preserving task-specific heads that existing pruning algorithms remove at low sparsity ratios, the circuits found by Contrastive-FLAP alone are too large to satisfy the minimality constraint required in circuit analysis. APP first applies Contrastive-FLAP to reduce the search space on required for circuit discovery algorithms by, on average, 56\%. Next, APP, applies traditional Path Patching on the remaining attention heads, leading to a speed up of 59.63\%-93.27\% compared to Path Patching applied to the dense model."}
        //{"id": "", "title": "", "venue": "", "url": "", "parent": "", "coauthors": [], "full_title": "", "summary": ""}
        ];

        build_garden(papers);
    </script>

</body>
</html>